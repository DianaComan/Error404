{"cells":[{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00000-e4afe5ef-0f5f-42c3-94ef-3988eee18245","output_cleared":false,"source_hash":"21a51d9c","execution_millis":440,"execution_start":1605632114792},"source":"import sklearn.metrics as metrics\n\ndef performanceMetrix(y_test, y_pred):\n    \n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    precision = metrics.precision_score(y_test, y_pred)\n    recall = metrics.recall_score(y_test, y_pred)\n    f1 = metrics.f1_score(y_test, y_pred)\n    cm = metrics.confusion_matrix(y_test, y_pred, labels=[0, 1])\n\n    print('Accuracy = ' + str('{0:.2f}'.format(accuracy * 100)) + '%')\n    print('Precision = ' + str('{0:.2f}'.format(precision * 100)) + '%')\n    print('Recall = ' + str('{0:.2f}'.format(recall * 100)) + '%')\n    print('F1 = ' + str('{0:.2f}'.format(f1 * 100)) + '%')\n    print('CM = [' + str(cm[0]) + '\\n      ' + str(cm[1]) + ']')\n    try:\n        auc = metrics.roc_auc_score(y_test, y_pred)\n        print('AUC = ' + str('{0:.2f}'.format(auc * 100)) + '%')\n    except ValueError:\n        pass\n","execution_count":1,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"59651194-2526-49d4-ae04-398473f66e8c","deepnote_execution_queue":[]}}
